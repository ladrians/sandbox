{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b2468c-289c-44f3-ae23-0c03e1ab0f1e",
   "metadata": {
    "id": "65b2468c-289c-44f3-ae23-0c03e1ab0f1e"
   },
   "source": [
    "# Inicialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccb131-7d4e-4072-afa4-4a3ebc208874",
   "metadata": {
    "id": "74ccb131-7d4e-4072-afa4-4a3ebc208874"
   },
   "source": [
    "Initialization of parameters, headers, and URL.\n",
    "Modify the global_token, global_evaluation_plan_Id, global_data_set_id  and global_url according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf54a62-814e-4ea6-9d15-81d35426e9a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1741292874903,
     "user": {
      "displayName": "Vicente Enrique Machaca Arceda",
      "userId": "04598897677493798070"
     },
     "user_tz": 300
    },
    "id": "9bf54a62-814e-4ea6-9d15-81d35426e9a6"
   },
   "outputs": [],
   "source": [
    "global_url = \"https://eval-api.qa.saia.ai\" # Aqui poner la url del ambiente, ejemplo: \"https://eval-api.saia.ai\" ($BASE_URL)\n",
    "global_token = \"qa_IZpuGDaGbCmt5SiK7FAdRUdUwnT6YWF3uSotCqOCpxoYrfuc7vPXmxUvmye7rVde25_bU1uKCIyaz1DTwStxtQ\" # Aqui poner el token de organizacion ($SAIA_PROJECT_APITOKEN)\n",
    "\n",
    "\n",
    "# No modificar estos valores\n",
    "import requests\n",
    "import urllib3\n",
    "import json\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {global_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ae5e5-db3a-410c-807c-e57fe76b987c",
   "metadata": {
    "id": "bf7ae5e5-db3a-410c-807c-e57fe76b987c"
   },
   "source": [
    "# Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60663f4-a47f-46e6-bbc0-aa4ad5bbac64",
   "metadata": {
    "id": "b60663f4-a47f-46e6-bbc0-aa4ad5bbac64"
   },
   "source": [
    "Create the dataset you want to use. The DataSetId will be obtained automatically for later use in the evaluation plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f707305-c8c0-4857-8300-361df4b6b9c8",
   "metadata": {
    "id": "7f707305-c8c0-4857-8300-361df4b6b9c8",
    "outputId": "bd0c814f-ed36-49ca-8367-1fc8bf4ba822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful. Server response:\n",
      "{\n",
      "    \"dataSetActive\": true,\n",
      "    \"dataSetCreateDate\": \"2025-03-10\",\n",
      "    \"dataSetDescription\": \"ls_01\",\n",
      "    \"dataSetId\": \"d9b62a1c-e6cd-4742-ab2b-ee8765289143\",\n",
      "    \"dataSetName\": \"ls_01\",\n",
      "    \"dataSetType\": \"T\",\n",
      "    \"dataSetUpdateDate\": \"2025-03-10\",\n",
      "    \"rows\": [\n",
      "        {\n",
      "            \"dataSetRowExpectedAnswer\": \"Artificial Intelligence\",\n",
      "            \"dataSetRowId\": \"5f96ba4b-1087-48cf-81bb-7834a7d01c0c\",\n",
      "            \"dataSetRowInput\": \"Artificial Intelligence\"\n",
      "        },\n",
      "        {\n",
      "            \"dataSetRowExpectedAnswer\": \"Hello Caro\",\n",
      "            \"dataSetRowId\": \"dace4add-a7c1-4bc8-afff-7dab06904bd7\",\n",
      "            \"dataSetRowInput\": \"Hola Caro\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Service URL\n",
    "url = f\"{global_url}/dataSetApi/dataSet\"\n",
    "\n",
    "# JSON data to be sent in the request body\n",
    "payload = {\n",
    "\t\"dataSetName\": \"ls_01\",\n",
    "\t\"dataSetDescription\": \"ls_01\",\n",
    "\t\"dataSetType\": \"T\",\n",
    "\t\"dataSetActive\": True,\n",
    "\t\"rows\": [\n",
    "\t\t{\n",
    "\t\t\t\"dataSetRowExpectedAnswer\": \"Artificial Intelligence\",\n",
    "\t\t\t\"dataSetRowContextDocument\": \"\",\n",
    "\t\t\t\"dataSetRowInput\": \"Artificial Intelligence\",\n",
    "\t\t\t\"expectedSources\": [\n",
    "\t\t\t],\n",
    "\t\t\t\"filterVariables\": [\n",
    "\t\t\t]\n",
    "\t\t},\n",
    "        {\n",
    "\t\t\t\"dataSetRowExpectedAnswer\": \"Hello Caro\",\n",
    "\t\t\t\"dataSetRowContextDocument\": \"\",\n",
    "\t\t\t\"dataSetRowInput\": \"Hola Caro\",\n",
    "\t\t\t\"expectedSources\": [\n",
    "\t\t\t],\n",
    "\t\t\t\"filterVariables\": [\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "\n",
    "\n",
    "# Make the POST request\n",
    "try:\n",
    "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request successful. Server response:\")\n",
    "        print(json.dumps(response.json(), indent=4 ,ensure_ascii=False))  # Print the response in JSON format\n",
    "\n",
    "        # Load the JSON response\n",
    "        response_data = response.json()\n",
    "\n",
    "        # Extract the dataSetId\n",
    "        data_set_id = response_data.get(\"dataSetId\")\n",
    "\n",
    "        # Save it in a global variable or file\n",
    "        # Global variable\n",
    "        global_data_set_id = data_set_id  # This will be available in the Notebook\n",
    "\n",
    "    else:\n",
    "        print(f\"Request error: {response.status_code}\")\n",
    "        print(\"Server response:\")\n",
    "        print(response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error connecting to the service: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8d6ca-7193-4156-81f1-ac692688ac40",
   "metadata": {
    "id": "dfe8d6ca-7193-4156-81f1-ac692688ac40"
   },
   "source": [
    "# List system metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57046721-c0d5-4ab3-9677-152ae9b914e1",
   "metadata": {
    "id": "57046721-c0d5-4ab3-9677-152ae9b914e1"
   },
   "source": [
    "List all system metrics. Copy the systemMetricId of the selected metric to evaluate in the evaluation plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "434de925-94b1-4b6c-b11b-11eabe82c362",
   "metadata": {
    "id": "434de925-94b1-4b6c-b11b-11eabe82c362",
    "outputId": "ead231b9-1c70-47b7-be29-12b826c6d429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service response:\n",
      "[{'systemMetricCategory': 'S', 'systemMetricEvaluatorId': '5c0aaa13-ef79-4740-a78a-e67dd68554d6', 'systemMetricEvaluatorName': 'Context Accuracy Evaluator', 'systemMetricEvaluatorVersion': 1, 'systemMetricId': '49a13ebd-371c-4573-a5a2-96ce0875c314', 'systemMetricMinScore': '0.50000', 'systemMetricName': 'Context Accuracy Metric', 'systemMetricRevision': 0, 'systemMetricServiceId': '1c612fdd-7330-4483-bfa9-ed5acbb76312'}, {'systemMetricCategory': 'S', 'systemMetricEvaluatorId': 'abebbd9e-ba37-4cea-a107-8f770acfe04a', 'systemMetricEvaluatorName': 'AccuracyAssistant', 'systemMetricEvaluatorVersion': 1, 'systemMetricId': '5504ac1f-b247-4fe3-8923-20ea61735038', 'systemMetricMinScore': '0.70000', 'systemMetricName': 'Accuracy', 'systemMetricRevision': 0, 'systemMetricServiceId': '7187d325-8b91-4ebb-b933-f3d85cc7af2b'}]\n"
     ]
    }
   ],
   "source": [
    "# Service URL\n",
    "url = f\"{global_url}/evaluationPlanApi/systemMetrics/\"\n",
    "\n",
    "try:\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, headers=headers, verify=False)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(\"Service response:\")\n",
    "        print(response.json())  # If the response is in JSON format\n",
    "    else:\n",
    "        print(f\"Request error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error connecting to the service: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7cbcb-8b8e-48b1-b572-d6efbc6c3e8b",
   "metadata": {
    "id": "f5c7cbcb-8b8e-48b1-b572-d6efbc6c3e8b"
   },
   "source": [
    "# Inicialization of SystemMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c3181-5240-4bbb-9894-873a36a84235",
   "metadata": {
    "id": "9b3c3181-5240-4bbb-9894-873a36a84235"
   },
   "source": [
    "Modify global_system_metric_id with the systemMetricId of the selected metric in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f21062e-d300-45f7-8cbb-bbf2329392af",
   "metadata": {
    "id": "3f21062e-d300-45f7-8cbb-bbf2329392af"
   },
   "outputs": [],
   "source": [
    "global_system_metric_id = \"5504ac1f-b247-4fe3-8923-20ea61735038\" # Aqui poner el systemMetricid seleccionado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19397819-d9b4-40cc-94bc-aefc86c1d62c",
   "metadata": {
    "id": "19397819-d9b4-40cc-94bc-aefc86c1d62c"
   },
   "source": [
    "# Evaluation plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152981bb-5561-42d4-80cb-33cf30840d72",
   "metadata": {
    "id": "152981bb-5561-42d4-80cb-33cf30840d72"
   },
   "source": [
    "Create the evaluation plan you want to use. The dataset used will be the one created previously, and the metric to be evaluated will be the one selected in the previous step. global_data_set_id and global_system_metric_id are already previously obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56b5b5e8-faea-4998-8b06-929bef9d969a",
   "metadata": {
    "id": "56b5b5e8-faea-4998-8b06-929bef9d969a",
    "outputId": "7886a3df-28ae-488d-84fa-db97349f2414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful. Server response:\n",
      "{\n",
      "    \"dataSetId\": \"d9b62a1c-e6cd-4742-ab2b-ee8765289143\",\n",
      "    \"evaluationPlanAssistantId\": \"22c11a61-6e06-43ba-a62b-21624a0a97fa\",\n",
      "    \"evaluationPlanAssistantName\": \"Translator01\",\n",
      "    \"evaluationPlanAssistantRevision\": \"1\",\n",
      "    \"evaluationPlanId\": \"34f5b785-8d7b-4c7c-9fc5-c2222d7daa2f\",\n",
      "    \"evaluationPlanName\": \"ls_plan_a\",\n",
      "    \"evaluationPlanType\": \"TextPromptAssistant\",\n",
      "    \"systemMetrics\": [\n",
      "        {\n",
      "            \"systemMetricCategory\": \"S\",\n",
      "            \"systemMetricEvaluatorId\": \"abebbd9e-ba37-4cea-a107-8f770acfe04a\",\n",
      "            \"systemMetricEvaluatorName\": \"AccuracyAssistant\",\n",
      "            \"systemMetricEvaluatorVersion\": 1,\n",
      "            \"systemMetricId\": \"5504ac1f-b247-4fe3-8923-20ea61735038\",\n",
      "            \"systemMetricMinScore\": \"0.70000\",\n",
      "            \"systemMetricName\": \"Accuracy\",\n",
      "            \"systemMetricRevision\": 0,\n",
      "            \"systemMetricServiceId\": \"7187d325-8b91-4ebb-b933-f3d85cc7af2b\",\n",
      "            \"systemMetricWeight\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Service URL\n",
    "url = f\"{global_url}/evaluationPlanApi/evaluationPlan\"\n",
    "\n",
    "# JSON data to be sent in the request body\n",
    "payload = {\n",
    "  \"evaluationPlanName\": \"ls_plan_a\", # Aca va el nombre del plan\n",
    "  \"evaluationPlanType\": \"TextPromptAssistant\", # Aca va el tipo de asistente: RAG Assistant, TextPromptAssistant o MultiModal\n",
    "  \"evaluationPlanAssistantId\": \"22c11a61-6e06-43ba-a62b-21624a0a97fa\", # Aca va el id del asistente, solo para evaluationPlanType = TextPromptAssistant o MultiModal\n",
    "  \"evaluationPlanAssistantName\": \"Translator01\", # Aca va el nombre del asistente, solo para evaluationPlanType = TextPromptAssistant o MultiModal\n",
    "  \"evaluationPlanAssistantRevision\": \"1\", # Aca va la revision del asistente, solo para evaluationPlanType = TextPromptAssistant o MultiModal\n",
    "  \"evaluationPlanProfileName\": \"\", # Aca va el nombre del perfil del asistente, solo para evaluationPlanType = RAG Assistant\n",
    "  \"dataSetId\": global_data_set_id,\n",
    "  \"systemMetrics\": [\n",
    "    {\n",
    "      \"systemMetricId\": global_system_metric_id,\n",
    "      \"systemMetricWeight\": \"1\" # Aca va el peso que va a tener esta metrica en el resultado total, la suma de los systemMetricWeight debe dar 1\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "try:\n",
    "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request successful. Server response:\")\n",
    "        print(json.dumps(response.json(), indent=4 ,ensure_ascii=False))  # Print the response in JSON format\n",
    "\n",
    "        # Load the JSON response\n",
    "        response_data = response.json()\n",
    "\n",
    "        # Extract the evaluation_plan_Id\n",
    "        evaluation_plan_Id = response_data.get(\"evaluationPlanId\")\n",
    "\n",
    "        # Save it in a global variable or file\n",
    "        # Global variable\n",
    "        global_evaluation_plan_Id = evaluation_plan_Id  # This will be available in the Notebook\n",
    "\n",
    "    else:\n",
    "        print(f\"Request error: {response.status_code}\")\n",
    "        print(\"Server response:\")\n",
    "        print(response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error connecting to the service: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823727a-5f51-4f80-8c39-5820d793fe74",
   "metadata": {
    "id": "7823727a-5f51-4f80-8c39-5820d793fe74"
   },
   "source": [
    "# Execute plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c943ab1-94e8-49d1-aafe-90d2513c56fb",
   "metadata": {
    "id": "3c943ab1-94e8-49d1-aafe-90d2513c56fb"
   },
   "source": [
    "Execute the previously created plan. The result evaluationResultId will be obtained automatically for later use. global_evaluation_plan_Id is already previously obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d79251ed-81ac-4572-b759-100d50945467",
   "metadata": {
    "id": "d79251ed-81ac-4572-b759-100d50945467",
    "outputId": "1fb4b775-bcf3-4871-d9ad-92ab6e5772e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful. Server response:\n",
      "{\n",
      "    \"evaluationResultId\": \"9d913a37-d4d5-4960-bc46-a0aecd96b555\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Service URL\n",
    "url = f\"{global_url}/evaluationPlanApi/evaluationPlan/{global_evaluation_plan_Id}\"\n",
    "\n",
    "# Make the POST request\n",
    "try:\n",
    "    response = requests.post(url,  headers=headers, verify=False)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request successful. Server response:\")\n",
    "        print(json.dumps(response.json(), indent=4 ,ensure_ascii=False))  # Print the response in JSON format\n",
    "\n",
    "        # Load the JSON response\n",
    "        response_data = response.json()\n",
    "\n",
    "        # Extract the evaluation_result_Id\n",
    "        evaluation_result_Id = response_data.get(\"evaluationResultId\")\n",
    "\n",
    "        # Save it in a global variable or file\n",
    "        # Global variable\n",
    "        global_evaluation_result_id = evaluation_result_Id  # This will be available in the Notebook\n",
    "\n",
    "    else:\n",
    "        print(f\"Request error: {response.status_code}\")\n",
    "        print(\"Server response:\")\n",
    "        print(response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error connecting to the service: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf50809-dfd5-46e9-a902-1eb33087af55",
   "metadata": {
    "id": "4cf50809-dfd5-46e9-a902-1eb33087af55"
   },
   "source": [
    "# Get evaluation result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfc6d8-0fd4-4123-9fbe-0a7095094426",
   "metadata": {
    "id": "a4bfc6d8-0fd4-4123-9fbe-0a7095094426"
   },
   "source": [
    "Retrieve the result of the previously executed plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c65185a6-b26a-43fe-8144-d19ecebb36af",
   "metadata": {
    "id": "c65185a6-b26a-43fe-8144-d19ecebb36af",
    "outputId": "8227130e-f965-4663-f356-a3c423728680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service response:\n",
      "{'dataSetId': 'd9b62a1c-e6cd-4742-ab2b-ee8765289143', 'evaluationPlanAssistantName': 'Translator01', 'evaluationPlanId': '34f5b785-8d7b-4c7c-9fc5-c2222d7daa2f', 'evaluationResultAssitantRevision': '1', 'evaluationResultChunckCount': 0, 'evaluationResultChunckSize': '0', 'evaluationResultCost': '0E-10', 'evaluationResultDuration': '0', 'evaluationResultEndDate': '2025-03-10', 'evaluationResultId': '9d913a37-d4d5-4960-bc46-a0aecd96b555', 'evaluationResultModelName': 'gpt-3.5-turbo-1106', 'evaluationResultProviderName': 'openai', 'evaluationResultStartDate': '2025-03-10', 'evaluationResultStatus': 'F', 'evaluationResultTemperature': 0.0, 'evaluationResultUploadFiles': False, 'evaluationResultaMaxTokens': '512', 'rows': [{'dataMetrics': [{'evaluationResultRowMetricFeedback': '', 'evaluationResultRowMetricResult': '', 'evaluationResultRowMetricScore': 1.0, 'systemMetricId': '5504ac1f-b247-4fe3-8923-20ea61735038'}], 'dataSetRowId': '5f96ba4b-1087-48cf-81bb-7834a7d01c0c', 'evaluationResultRowCost': '0.0000420000', 'evaluationResultRowEndDate': '2025-03-10T13:44:25', 'evaluationResultRowOutput': 'Artificial Intelligence', 'evaluationResultRowStartDate': '2025-03-10T13:44:25', 'evaluationResultRowStatus': 'F'}, {'dataMetrics': [{'evaluationResultRowMetricFeedback': '', 'evaluationResultRowMetricResult': '', 'evaluationResultRowMetricScore': 1.0, 'systemMetricId': '5504ac1f-b247-4fe3-8923-20ea61735038'}], 'dataSetRowId': 'dace4add-a7c1-4bc8-afff-7dab06904bd7', 'evaluationResultRowCost': '0.0000450000', 'evaluationResultRowEndDate': '2025-03-10T13:44:26', 'evaluationResultRowOutput': 'Hola Caro', 'evaluationResultRowStartDate': '2025-03-10T13:44:25', 'evaluationResultRowStatus': 'F'}]}\n"
     ]
    }
   ],
   "source": [
    "# Service URL\n",
    "url = f\"{global_url}/evaluationResultApi/evaluationResult/{global_evaluation_result_id}\"\n",
    "\n",
    "try:\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, headers=headers, verify=False)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(\"Service response:\")\n",
    "        print(response.json())  # If the response is in JSON format\n",
    "    else:\n",
    "        print(f\"Request error: {response.status_code}\")\n",
    "        print(response.text)  # Displays the response content in case of an error\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error connecting to the service: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44396e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
