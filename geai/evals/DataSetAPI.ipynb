{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "rfZyeicrw4XF",
      "metadata": {
        "id": "rfZyeicrw4XF"
      },
      "source": [
        "This guide explains how to use the DataSet API to manage datasets for evaluating your AI Assistants. You'll find examples for each endpoint, demonstrating how to interact with the API using Python."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42356917-a5ce-446f-ab35-18e050cbbce9",
      "metadata": {
        "id": "42356917-a5ce-446f-ab35-18e050cbbce9"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Js33pDmxGP0",
      "metadata": {
        "id": "4Js33pDmxGP0"
      },
      "source": [
        "Before you begin, set up your environment with the necessary parameters:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4o65s9AzxKBE",
      "metadata": {
        "id": "4o65s9AzxKBE"
      },
      "source": [
        "### Set the base URL and API token\n",
        "\n",
        "1. `global_url`:  Set this to the URL of your Globant Enterprise AI environment (e.g., \"https://eval-api.saia.ai\"). This is represented by the `$BASE_URL` variable.\n",
        "\n",
        "2. `global_token`:  Provide your organization's API token, represented by the `$SAIA_PROJECT_APITOKEN` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b1a43ca2-ace0-4d8f-9026-f7edaaba2dcd",
      "metadata": {
        "id": "b1a43ca2-ace0-4d8f-9026-f7edaaba2dcd"
      },
      "outputs": [],
      "source": [
        "global_url = \"https://eval-api.saia.ai\"\n",
        "global_token = \"geai_-NfFwi7jgdkGA6VAP0gR4ZtQyiaXKHgpQu5moZtCF_3enyAqsAKXDFMEXmv0vfrtuLipPjKSlArvyKJpZ0_9yg\"\n",
        "\n",
        "\n",
        "import requests\n",
        "import urllib3\n",
        "import json\n",
        "\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {global_token}\",\n",
        "    \"Accept\": \"application/json; charset=UTF-8\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf9c6591-d3b7-48d1-bcd9-716ddb8215a5",
      "metadata": {
        "id": "cf9c6591-d3b7-48d1-bcd9-716ddb8215a5"
      },
      "source": [
        "# Working with Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zh1fNuetDsaT",
      "metadata": {
        "id": "Zh1fNuetDsaT"
      },
      "source": [
        "The DataSet API provides a comprehensive set of endpoints for managing the datasets you'll use to evaluate your AI Assistants. You can create, retrieve, update, and delete datasets, as well as manage the individual rows within each dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91bfe4da-64d8-417b-82e2-a75724b562ae",
      "metadata": {
        "id": "91bfe4da-64d8-417b-82e2-a75724b562ae"
      },
      "source": [
        "## Listing Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vOxXH7i8x9AT",
      "metadata": {
        "id": "vOxXH7i8x9AT"
      },
      "source": [
        "This endpoint retrieves a list of all datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a4092da1-6e25-4be5-924f-6f29e0f85c7a",
      "metadata": {
        "id": "a4092da1-6e25-4be5-924f-6f29e0f85c7a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Service response:\n",
            "[{'dataSetActive': True, 'dataSetCreateDate': '2025-05-12', 'dataSetDescription': 'geai_01', 'dataSetId': 'fbaa7af6-1f11-4e7b-b24d-fd5071759fc4', 'dataSetName': 'geai_01', 'dataSetType': 'T', 'dataSetUpdateDate': '2025-05-12', 'rows': [{'dataSetRowContextDocument': 'Globant Enterprise AI Overview', 'dataSetRowExpectedAnswer': 'Globant Enterprise AI is a business platform designed to facilitate the implementation of AI assistants tailored to specific needs and areas of expertise. It allows users to create AI assistants that can integrate and interact with current operations, processes, systems, and documents, paving the way for innovation and productivity. A key feature of Globant Enterprise AI is the ability to select a Large Language Model (LLM) and switch to another without needing to change the definitions of existing assistants. This platform acts as a secure bridge, connecting enterprise applications to LLMs while ensuring the protection of data, which will not be made public or used by the LLMs.\\n\\nAdditionally, it offers various features like monitoring access to LLMs, providing a web interface branded by the organization, supervising costs, managing quotas, and creating APIs to facilitate AI capabilities in corporate software. The platform also emphasizes maintaining security, scalability, and observability in its operations', 'dataSetRowId': '138b9984-3523-4eb3-8315-2b1100804629', 'dataSetRowInput': 'What is Globant Enterprise AI?'}, {'dataSetRowContextDocument': 'Chat with Data Assistant Use Guidelines', 'dataSetRowExpectedAnswer': 'To get started with the Chat with Data Assistant, you can follow these steps:\\n\\n1. **Access the Backoffice**: Log in to the [Globant Enterprise AI Backoffice](https://wiki.genexus.com/enterprise-ai/wiki?42) using your organization administrator credentials.\\n \\n2. **Upload Metadata**: Upload the necessary metadata in a file with an **.export** extension.\\n\\n3. **Configure Database Connection**: Set up the connection options for a supported DBMS (currently includes SQL Server, MySQL, PostgreSQL, Oracle, and more).\\n\\n4. **Select Your Assistant**: After configuration, navigate to the **Frontend** and select the Chat with Data Assistant you created.\\n\\n5. **Query Using Natural Language**: You can now make queries using natural language directly from the frontend, greatly improving the data search and retrieval process.\\n\\n> **Note**: Ensure that the database is accessible via the internet and that the required ADO.NET drivers are installed for the connection.\\n\\nFor more detailed information, refer to the guide on [Chat with Data Assistant](https://wiki.genexus.com/enterprise-ai/wiki?159).', 'dataSetRowId': '4987c170-6ddd-47d7-8de2-27dacc172e2f', 'dataSetRowInput': 'How do I get started with the Chat with Data Assistant?'}, {'dataSetRowContextDocument': 'Globant Enterprise AI Backoffice', 'dataSetRowExpectedAnswer': 'To use a flow assistant in the Globant Enterprise AI Backoffice, you can follow these steps:\\n\\n1. **Navigate to the Flows Section**: Access the Flows section from the Project Options in the Backoffice Menu. This section allows you to create customized conversational flows that enhance interactions with end users.\\n\\n2. **Create a Flow**: In the Flows section, you can create new conversational flows by integrating different specialized assistants tailored to specific tasks or user interactions.\\n\\n3. **Define the Flow Steps**: Customize the various steps in your flow to dictate how the interaction with users will progress. This may include defining the questions asked, the responses provided, and how different assistants interact within the flow.\\n\\n4. **Test Your Flow**: Once your flow is created, you can test it using the Playground. The Playground provides an interactive environment to see how users will interact with the configured assistants in real-time.\\n\\n5. **Adjust Configurations**: Based on the testing in the Playground, you can optimize and adjust the configurations of your flow to enhance user experience and ensure efficient resource utilization.\\n\\nFor more detailed options and functionalities about flows, refer to the relevant section in the documentation [here](https://wiki.genexus.com/enterprise-ai/wiki?42) [1](https://wiki.genexus.com/enterprise-ai/wiki?42).', 'dataSetRowId': '6af44a97-3be0-4851-bc55-7b219296b0b7', 'dataSetRowInput': 'how do I use a flow assistant?'}, {'dataSetRowContextDocument': 'Assistants', 'dataSetRowExpectedAnswer': 'To use the Data Analyst Assistant, you can analyze datasets based on CSV files to obtain insights or create forecasts using natural language queries. This assistant allows you to ask questions about the data, and it will interpret your queries to provide relevant results.\\n\\nFor more details, you can refer to the [Assistants documentation](https://wiki.genexus.com/enterprise-ai/wiki?566) which outlines the capabilities and features of various assistants, including the Data Analyst Assistant [here](89.html) for specific instructions related to it. This information is found in the context discussing assistants. [1](https://wiki.genexus.com/enterprise-ai/wiki?566)', 'dataSetRowId': 'a75ace49-98da-4d6f-9f1d-10c2229a0589', 'dataSetRowInput': 'How do I use the Data Analyst assistant?'}]}]\n"
          ]
        }
      ],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSets\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Displays the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375f9bc3-3dfd-4f96-832c-8d4b03c65fe3",
      "metadata": {
        "id": "375f9bc3-3dfd-4f96-832c-8d4b03c65fe3"
      },
      "source": [
        "## Creating a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WKYQBQCqyGKC",
      "metadata": {
        "id": "WKYQBQCqyGKC"
      },
      "source": [
        "This endpoint creates a new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea58b71-775c-4701-84d1-f60d71ab9d60",
      "metadata": {
        "id": "0ea58b71-775c-4701-84d1-f60d71ab9d60",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet\"\n",
        "\n",
        "# JSON data to be sent in the request body\n",
        "payload = {\n",
        "\t\"dataSetName\": \"Test Dataset\",\n",
        "\t\"dataSetDescription\": \"the policy you use\",\n",
        "\t\"dataSetType\": \"T\",\n",
        "\t\"dataSetActive\": True,\n",
        "\t\"rows\": [\n",
        "\t]\n",
        "}\n",
        "\n",
        "# Make the POST request\n",
        "try:\n",
        "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4, ensure_ascii=False))  # Print the response in JSON format\n",
        "\n",
        "        # Load the JSON response\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Extract the dataSetId\n",
        "        data_set_id = response_data.get(\"dataSetId\")\n",
        "\n",
        "        # Save it in a global variable or file\n",
        "        # Global variable\n",
        "        global_data_set_id = data_set_id  # This will be available in the Notebook\n",
        "\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc704b0d-caca-4a58-93f6-acdb8f7f0abf",
      "metadata": {
        "id": "bc704b0d-caca-4a58-93f6-acdb8f7f0abf"
      },
      "source": [
        "## Retrieving a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kg9rz4hVyNL7",
      "metadata": {
        "id": "kg9rz4hVyNL7"
      },
      "source": [
        "This endpoint retrieves a specific dataset by its `Id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c687cf21-bbdf-47c7-aad8-4ad39b832c5b",
      "metadata": {
        "id": "c687cf21-bbdf-47c7-aad8-4ad39b832c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Service response:\n",
            "{'dataSetActive': True, 'dataSetCreateDate': '2025-05-12', 'dataSetDescription': 'geai_01', 'dataSetId': 'fbaa7af6-1f11-4e7b-b24d-fd5071759fc4', 'dataSetName': 'geai_01', 'dataSetType': 'T', 'dataSetUpdateDate': '2025-05-12', 'rows': [{'dataSetRowContextDocument': 'Globant Enterprise AI Overview', 'dataSetRowExpectedAnswer': 'Globant Enterprise AI is a business platform designed to facilitate the implementation of AI assistants tailored to specific needs and areas of expertise. It allows users to create AI assistants that can integrate and interact with current operations, processes, systems, and documents, paving the way for innovation and productivity. A key feature of Globant Enterprise AI is the ability to select a Large Language Model (LLM) and switch to another without needing to change the definitions of existing assistants. This platform acts as a secure bridge, connecting enterprise applications to LLMs while ensuring the protection of data, which will not be made public or used by the LLMs.\\n\\nAdditionally, it offers various features like monitoring access to LLMs, providing a web interface branded by the organization, supervising costs, managing quotas, and creating APIs to facilitate AI capabilities in corporate software. The platform also emphasizes maintaining security, scalability, and observability in its operations', 'dataSetRowId': '138b9984-3523-4eb3-8315-2b1100804629', 'dataSetRowInput': 'What is Globant Enterprise AI?'}, {'dataSetRowContextDocument': 'Chat with Data Assistant Use Guidelines', 'dataSetRowExpectedAnswer': 'To get started with the Chat with Data Assistant, you can follow these steps:\\n\\n1. **Access the Backoffice**: Log in to the [Globant Enterprise AI Backoffice](https://wiki.genexus.com/enterprise-ai/wiki?42) using your organization administrator credentials.\\n \\n2. **Upload Metadata**: Upload the necessary metadata in a file with an **.export** extension.\\n\\n3. **Configure Database Connection**: Set up the connection options for a supported DBMS (currently includes SQL Server, MySQL, PostgreSQL, Oracle, and more).\\n\\n4. **Select Your Assistant**: After configuration, navigate to the **Frontend** and select the Chat with Data Assistant you created.\\n\\n5. **Query Using Natural Language**: You can now make queries using natural language directly from the frontend, greatly improving the data search and retrieval process.\\n\\n> **Note**: Ensure that the database is accessible via the internet and that the required ADO.NET drivers are installed for the connection.\\n\\nFor more detailed information, refer to the guide on [Chat with Data Assistant](https://wiki.genexus.com/enterprise-ai/wiki?159).', 'dataSetRowId': '4987c170-6ddd-47d7-8de2-27dacc172e2f', 'dataSetRowInput': 'How do I get started with the Chat with Data Assistant?'}, {'dataSetRowContextDocument': 'Globant Enterprise AI Backoffice', 'dataSetRowExpectedAnswer': 'To use a flow assistant in the Globant Enterprise AI Backoffice, you can follow these steps:\\n\\n1. **Navigate to the Flows Section**: Access the Flows section from the Project Options in the Backoffice Menu. This section allows you to create customized conversational flows that enhance interactions with end users.\\n\\n2. **Create a Flow**: In the Flows section, you can create new conversational flows by integrating different specialized assistants tailored to specific tasks or user interactions.\\n\\n3. **Define the Flow Steps**: Customize the various steps in your flow to dictate how the interaction with users will progress. This may include defining the questions asked, the responses provided, and how different assistants interact within the flow.\\n\\n4. **Test Your Flow**: Once your flow is created, you can test it using the Playground. The Playground provides an interactive environment to see how users will interact with the configured assistants in real-time.\\n\\n5. **Adjust Configurations**: Based on the testing in the Playground, you can optimize and adjust the configurations of your flow to enhance user experience and ensure efficient resource utilization.\\n\\nFor more detailed options and functionalities about flows, refer to the relevant section in the documentation [here](https://wiki.genexus.com/enterprise-ai/wiki?42) [1](https://wiki.genexus.com/enterprise-ai/wiki?42).', 'dataSetRowId': '6af44a97-3be0-4851-bc55-7b219296b0b7', 'dataSetRowInput': 'how do I use a flow assistant?'}, {'dataSetRowContextDocument': 'Assistants', 'dataSetRowExpectedAnswer': 'To use the Data Analyst Assistant, you can analyze datasets based on CSV files to obtain insights or create forecasts using natural language queries. This assistant allows you to ask questions about the data, and it will interpret your queries to provide relevant results.\\n\\nFor more details, you can refer to the [Assistants documentation](https://wiki.genexus.com/enterprise-ai/wiki?566) which outlines the capabilities and features of various assistants, including the Data Analyst Assistant [here](89.html) for specific instructions related to it. This information is found in the context discussing assistants. [1](https://wiki.genexus.com/enterprise-ai/wiki?566)', 'dataSetRowId': 'a75ace49-98da-4d6f-9f1d-10c2229a0589', 'dataSetRowInput': 'How do I use the Data Analyst assistant?'}]}\n"
          ]
        }
      ],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Displays the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87887154-fb44-46f0-8ca2-832d93d276e6",
      "metadata": {
        "id": "87887154-fb44-46f0-8ca2-832d93d276e6"
      },
      "source": [
        "## Updating a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3J7_VmjiyUeD",
      "metadata": {
        "id": "3J7_VmjiyUeD"
      },
      "source": [
        "This endpoint updates an existing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faf554b-ba11-4036-ae5c-a6302b5d447a",
      "metadata": {
        "id": "9faf554b-ba11-4036-ae5c-a6302b5d447a"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}\"\n",
        "\n",
        "# JSON data to be sent in the request body\n",
        "payload = {\n",
        "    \"dataSetName\": \"TEST_B\",\n",
        "    \"dataSetDescription\": \"TEST_B\",\n",
        "    \"dataSetType\": \"T\",\n",
        "    \"dataSetActive\": True\n",
        "}\n",
        "\n",
        "# Make the PUT request\n",
        "try:\n",
        "    response = requests.put(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1af94580",
      "metadata": {},
      "outputs": [],
      "source": [
        "global_data_set_id = \"e2057ff6-4b34-45ea-a464-8e51474c2c63\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a44e49a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "global_data_set_id = \"fbaa7af6-1f11-4e7b-b24d-fd5071759fc4\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ec8653-4c03-487f-92c4-70e5d7541cc2",
      "metadata": {
        "id": "b8ec8653-4c03-487f-92c4-70e5d7541cc2"
      },
      "source": [
        "## Deleting a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mahHK5PdyZdy",
      "metadata": {
        "id": "mahHK5PdyZdy"
      },
      "source": [
        "This endpoint deletes a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7527e1ad-ffa6-41cb-8a84-4bca3c229e87",
      "metadata": {
        "id": "7527e1ad-ffa6-41cb-8a84-4bca3c229e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Service response:\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}\"\n",
        "\n",
        "try:\n",
        "    # Make the DELETE request\n",
        "    response = requests.delete(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Displays the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a080d2f4-f029-430f-9922-06960c0ea2e6",
      "metadata": {
        "id": "a080d2f4-f029-430f-9922-06960c0ea2e6"
      },
      "source": [
        "# Working with Dataset Rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EyKpLjEpydbT",
      "metadata": {
        "id": "EyKpLjEpydbT"
      },
      "source": [
        "The DataSet API also provides endpoints for managing individual rows within a dataset. These endpoints allow you to:\n",
        "\n",
        "* Create new rows in a dataset.\n",
        "* List rows for a specific dataset.\n",
        "* Retrieve, update, and delete individual dataset rows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e500e3a0-af91-454d-bd16-0344057e70b3",
      "metadata": {
        "id": "e500e3a0-af91-454d-bd16-0344057e70b3"
      },
      "source": [
        "## Inserting a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T0gVVkOQ6var",
      "metadata": {
        "id": "T0gVVkOQ6var"
      },
      "source": [
        "This endpoint creates a new dataset to which you can then add rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae832b74-1d8b-49bc-9a0c-92453bc24b01",
      "metadata": {
        "id": "ae832b74-1d8b-49bc-9a0c-92453bc24b01",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet\"\n",
        "\n",
        "# JSON data to be sent in the request body\n",
        "payload = {\n",
        "    \"dataSetName\": \"TESTA_A\",\n",
        "    \"dataSetDescription\": \"TEST_A\",\n",
        "    \"dataSetType\": \"T\",\n",
        "    \"dataSetActive\": True,\n",
        "    \"rows\": []\n",
        "}\n",
        "\n",
        "# Make the POST request\n",
        "try:\n",
        "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "\n",
        "        # Load the JSON response\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Extract the dataSetId\n",
        "        data_set_id = response_data.get(\"dataSetId\")\n",
        "\n",
        "        # Store it in a global variable or file\n",
        "        global_data_set_id = data_set_id  # This will be available in the Notebook\n",
        "\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55210f15-77db-460d-8d82-227ada1cd8ac",
      "metadata": {
        "id": "55210f15-77db-460d-8d82-227ada1cd8ac"
      },
      "source": [
        "## Listing Dataset Rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FmwmDpQXzwdp",
      "metadata": {
        "id": "FmwmDpQXzwdp"
      },
      "source": [
        "You can retrieve a list of rows for a specific dataset using the following endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a8602c-593e-4b0f-8a12-0983cf591453",
      "metadata": {
        "id": "a4a8602c-593e-4b0f-8a12-0983cf591453"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRows\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url,  headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Show the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0beee5d8-d352-4599-9203-a45bc6e23dc5",
      "metadata": {
        "id": "0beee5d8-d352-4599-9203-a45bc6e23dc5"
      },
      "source": [
        "## Inserting a Dataset Row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5y0aLAUz63TL",
      "metadata": {
        "id": "5y0aLAUz63TL"
      },
      "source": [
        "This endpoint adds a new row to a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b11bc6-eb46-4f33-b186-d81a1bd21566",
      "metadata": {
        "id": "f6b11bc6-eb46-4f33-b186-d81a1bd21566"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow\"\n",
        "\n",
        "# JSON data to be sent in the request body\n",
        "payload = {\n",
        "    \"dataSetRowExpectedAnswer\": \"ANSWER_B\",\n",
        "    \"dataSetRowContextDocument\": \"\",\n",
        "    \"dataSetRowInput\": \"INPUT_B\",\n",
        "    \"expectedSources\": [\n",
        "        {\n",
        "            \"dataSetExpectedSourceName\": \"NAME_B\",\n",
        "            \"dataSetexpectedSourceExtention\": \"JSON\",\n",
        "            \"dataSetExpectedSourceValue\": \"VALUE_B\"\n",
        "        }\n",
        "    ],\n",
        "    \"filterVariables\": [\n",
        "        {\n",
        "            \"dataSetMetadataType\": \"V\",\n",
        "            \"dataSetRowFilterKey\": \"KEY_B\",\n",
        "            \"dataSetRowFilterValue\": \"VALUE_B\",\n",
        "            \"dataSetRowFilterOperator\": \"OPERATOR_B\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Make the POST request\n",
        "try:\n",
        "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "\n",
        "        # Load the JSON response\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Extract the dataSetRowId\n",
        "        data_set_row_id = response_data.get(\"dataSetRowId\")\n",
        "\n",
        "        # Store it in a global variable or a file\n",
        "        # Global variable\n",
        "        global_data_set_row_id = data_set_row_id  # This will be available in the Notebook\n",
        "\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a596cd47-4a7e-44d1-886f-7f6c6e9cdce2",
      "metadata": {
        "id": "a596cd47-4a7e-44d1-886f-7f6c6e9cdce2"
      },
      "source": [
        "## Retrieving a Dataset Row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wYVL31No67li",
      "metadata": {
        "id": "wYVL31No67li"
      },
      "source": [
        "This endpoint retrieves a specific dataset row by its `Id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b78b5e-9459-4aee-9f33-51cd76cf8a4a",
      "metadata": {
        "id": "39b78b5e-9459-4aee-9f33-51cd76cf8a4a"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{data_set_row_id}\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Display the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb8f6b51-f128-4c81-8900-05bf3c6a8c11",
      "metadata": {
        "id": "cb8f6b51-f128-4c81-8900-05bf3c6a8c11"
      },
      "source": [
        "## Updating a Dataset Row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Ku6_ty47DKa",
      "metadata": {
        "id": "5Ku6_ty47DKa"
      },
      "source": [
        "This endpoint updates an existing dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb82b4a8-39e6-4c57-9f8a-6e49ef291f3f",
      "metadata": {
        "id": "fb82b4a8-39e6-4c57-9f8a-6e49ef291f3f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{data_set_row_id}\"\n",
        "\n",
        "# JSON data to be sent in the request body\n",
        "payload = {\n",
        "    \"dataSetRowInput\": \"INPUT_C\",\n",
        "    \"dataSetRowExpectedAnswer\": \"ANSWER_C\",\n",
        "    \"dataSetRowContextDocument\": \"\"\n",
        "}\n",
        "\n",
        "# Make the PUT request\n",
        "try:\n",
        "    response = requests.put(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd8d074-038c-4fea-8aaf-6a84f5b769c9",
      "metadata": {
        "id": "4cd8d074-038c-4fea-8aaf-6a84f5b769c9"
      },
      "source": [
        "## Deleting a Dataset Row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2k1ahwVr7G6D",
      "metadata": {
        "id": "2k1ahwVr7G6D"
      },
      "source": [
        "This endpoint deletes a dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2003fc7a-b135-42b1-85f6-aa9c91aa863d",
      "metadata": {
        "id": "2003fc7a-b135-42b1-85f6-aa9c91aa863d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{data_set_row_id}\"\n",
        "\n",
        "try:\n",
        "    # Make the DELETE request\n",
        "    response = requests.delete(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Show the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd76818-5351-4c83-87d4-4d5e475fc544",
      "metadata": {
        "id": "4cd76818-5351-4c83-87d4-4d5e475fc544"
      },
      "source": [
        "# Uploading Data via Files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6WkgFJMP7Y3j",
      "metadata": {
        "id": "6WkgFJMP7Y3j"
      },
      "source": [
        "The DataSet API allows you to efficiently populate datasets by uploading data directly from JSON files. You can upload either a complete dataset or multiple rows to an existing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K4bSkeN-8Dxy",
      "metadata": {
        "id": "K4bSkeN-8Dxy"
      },
      "source": [
        "## Uploading a Complete Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4xTdUSMS8GOi",
      "metadata": {
        "id": "4xTdUSMS8GOi"
      },
      "source": [
        "This endpoint allows you to create a new dataset by uploading data from a JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "549be85e-e0a7-44c5-bae1-42c6284424a5",
      "metadata": {
        "id": "549be85e-e0a7-44c5-bae1-42c6284424a5"
      },
      "outputs": [],
      "source": [
        "# API URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/FileUpload\"\n",
        "\n",
        "# File to be uploaded\n",
        "file_name = \"DataSetExample.json\"  # Replace with your file path\n",
        "\n",
        "# Send the POST request with JSON data\n",
        "try:\n",
        "    # Read the JSON file\n",
        "    with open(file_name, 'r') as file:\n",
        "        json_data = json.load(file)  # Load JSON from the file\n",
        "\n",
        "    # Send the POST request with the JSON data\n",
        "    response = requests.post(url, json=json_data, headers=headers, verify=False)\n",
        "\n",
        "    # Print the response code and content\n",
        "    print(f\"Response Code: {response.status_code}\")\n",
        "    print(response.text)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_name} was not found in the notebook directory.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Request error occurred: {e}\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error decoding JSON from the file. Please check the file format.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498a5dc1-0ffc-4871-987a-a189faad7f5d",
      "metadata": {
        "id": "498a5dc1-0ffc-4871-987a-a189faad7f5d"
      },
      "source": [
        "## Uploading Multiple Dataset Rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SZ0oXK1V-CGf",
      "metadata": {
        "id": "SZ0oXK1V-CGf"
      },
      "source": [
        "You can use this endpoint to add multiple rows to an existing dataset by uploading data from a JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a248cde4-faba-4e64-98f5-96a9386964b3",
      "metadata": {
        "id": "a248cde4-faba-4e64-98f5-96a9386964b3"
      },
      "outputs": [],
      "source": [
        "# API URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/FileUpload\"\n",
        "\n",
        "# File to be uploaded\n",
        "file_name = \"Test.json\"  # Replace with your file path\n",
        "\n",
        "# Send the POST request with JSON data\n",
        "try:\n",
        "    # Read the JSON file\n",
        "    with open(file_name, 'r') as file:\n",
        "        json_data = json.load(file)  # Load JSON from the file\n",
        "\n",
        "    # Send the POST request with the JSON data\n",
        "    response = requests.post(url, json=json_data, headers=headers, verify=False)\n",
        "\n",
        "    # Print the response code and content\n",
        "    print(f\"Response Code: {response.status_code}\")\n",
        "    print(response.text)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_name} was not found in the notebook directory.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Request error occurred: {e}\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error decoding JSON from the file. Please check the file format.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a936bbf-79d7-4a70-a41c-268d04abb61f",
      "metadata": {
        "id": "9a936bbf-79d7-4a70-a41c-268d04abb61f"
      },
      "source": [
        "# Managing Expected Sources and Filter Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aKXBBjhh-fGf",
      "metadata": {
        "id": "aKXBBjhh-fGf"
      },
      "source": [
        "The API also offers endpoints for managing expected sources and filter variables associated with dataset rows. You can do the following:\n",
        "\n",
        "*  **Expected Sources:** Create, list, retrieve, update, and delete expected sources for a dataset row.\n",
        "*  **Filter Variables:** Create, list, retrieve, update, and delete filter variables for a dataset row."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z-dOghQn_gxe",
      "metadata": {
        "id": "z-dOghQn_gxe"
      },
      "source": [
        "## Working with Expected Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QAS1Ot5E_j4O",
      "metadata": {
        "id": "QAS1Ot5E_j4O"
      },
      "source": [
        "Expected sources provide information about the expected origins of the data in a dataset row. You can use the following endpoints to manage them:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014a2991-d826-4a32-8711-adac60865693",
      "metadata": {
        "id": "014a2991-d826-4a32-8711-adac60865693"
      },
      "source": [
        "###  Inserting a Dataset Row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mZdLgdFv_o5u",
      "metadata": {
        "id": "mZdLgdFv_o5u"
      },
      "source": [
        "This endpoint adds a new row to a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5458e2-4d0d-4111-b500-73746e8fc2e9",
      "metadata": {
        "id": "ff5458e2-4d0d-4111-b500-73746e8fc2e9"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow\"\n",
        "\n",
        "# JSON data to send in the request body\n",
        "payload = {\n",
        "    \"dataSetRowExpectedAnswer\": \"ANSWER_B\",\n",
        "    \"dataSetRowContextDocument\": \"\",\n",
        "    \"dataSetRowInput\": \"INPUT_B\",\n",
        "    \"expectedSources\": [],\n",
        "    \"filterVariables\": []\n",
        "}\n",
        "\n",
        "# Make the POST request\n",
        "try:\n",
        "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "\n",
        "        # Load the JSON response\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Extract the dataSetRowId\n",
        "        data_set_row_id = response_data.get(\"dataSetRowId\")\n",
        "\n",
        "        # Save it to a global variable or file\n",
        "        # Global variable\n",
        "        global_data_set_row_id = data_set_row_id  # This will be available in the notebook\n",
        "\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98da2ce3-7809-4403-9e5e-4ab9ac9bc9dc",
      "metadata": {
        "id": "98da2ce3-7809-4403-9e5e-4ab9ac9bc9dc"
      },
      "source": [
        "### Listing Expected Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VJjWv-Z6Awhs",
      "metadata": {
        "id": "VJjWv-Z6Awhs"
      },
      "source": [
        "This endpoint retrieves a list of all expected sources for a specific dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d646095-2793-472a-adb8-ee45bc9a5315",
      "metadata": {
        "id": "9d646095-2793-472a-adb8-ee45bc9a5315"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowExpectedSources\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)  # Display the content of the response in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b0681b-ddd7-4891-8701-c68e753b745e",
      "metadata": {
        "id": "e6b0681b-ddd7-4891-8701-c68e753b745e"
      },
      "source": [
        "### Inserting an Expected Source"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QngpR67DBa00",
      "metadata": {
        "id": "QngpR67DBa00"
      },
      "source": [
        "This endpoint adds a new expected source to a dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e25f821-5cad-480a-ac32-eb4c22dcd522",
      "metadata": {
        "id": "0e25f821-5cad-480a-ac32-eb4c22dcd522"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowExpectedSource\"\n",
        "\n",
        "# JSON data to send in the POST request\n",
        "payload = {\n",
        "    \"dataSetExpectedSourceName\": \"NAME_C\",\n",
        "    \"dataSetexpectedSourceExtention\": \"JSON\",\n",
        "    \"dataSetExpectedSourceValue\": \"VALUE_C\"\n",
        "}\n",
        "\n",
        "# Make the POST request\n",
        "try:\n",
        "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "\n",
        "        # Load the JSON response\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Extract the dataSetExpectedSourceId\n",
        "        data_set_row_expected_source_id = response_data.get(\"dataSetExpectedSourceId\")\n",
        "\n",
        "        # Store it in a global variable or file\n",
        "        # Global variable\n",
        "        global_data_set_row_expected_source_id = data_set_row_expected_source_id  # This will be available in the Notebook\n",
        "\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac9080c-6178-49e9-b5de-a1e9992af476",
      "metadata": {
        "id": "4ac9080c-6178-49e9-b5de-a1e9992af476"
      },
      "source": [
        "### Retrieving an Expected Source"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZJgQFjyyBfyb",
      "metadata": {
        "id": "ZJgQFjyyBfyb"
      },
      "source": [
        "This endpoint retrieves a specific expected source by its `Id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92e01993-cacd-4b0d-8cc9-04e41123d0a0",
      "metadata": {
        "id": "92e01993-cacd-4b0d-8cc9-04e41123d0a0"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowExpectedSource/{global_data_set_row_expected_source_id}\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Error in the request: {response.status_code}\")\n",
        "        print(response.text)  # Print the response content in case of an error\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c8fb67e-41ec-48b0-8ead-07a6a78347b6",
      "metadata": {
        "id": "7c8fb67e-41ec-48b0-8ead-07a6a78347b6"
      },
      "source": [
        "### Updating an Expected Source"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZGyxvUkzBnDr",
      "metadata": {
        "id": "ZGyxvUkzBnDr"
      },
      "source": [
        "This endpoint updates an existing expected source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acf9f36-c9aa-443b-9794-b1c14b4c76a9",
      "metadata": {
        "id": "5acf9f36-c9aa-443b-9794-b1c14b4c76a9"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowExpectedSource/{global_data_set_row_expected_source_id}\"\n",
        "\n",
        "# JSON data to send in the body of the request\n",
        "payload = {\n",
        "    \"dataSetExpectedSourceName\": \"NAME_D\",\n",
        "    \"dataSetexpectedSourceExtention\": \"TXT\",\n",
        "    \"dataSetExpectedSourceValue\": \"VALUE_D\"\n",
        "}\n",
        "\n",
        "# Make the PUT request\n",
        "try:\n",
        "    response = requests.put(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96eb1ffe-11d3-431d-b024-0bec6897b559",
      "metadata": {
        "id": "96eb1ffe-11d3-431d-b024-0bec6897b559"
      },
      "source": [
        "### Deleting an Expected Source"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dX0teRBSB-YC",
      "metadata": {
        "id": "dX0teRBSB-YC"
      },
      "source": [
        "This endpoint removes an expected source from a dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76179b25-b6ba-4156-8bf6-47747593e7ac",
      "metadata": {
        "id": "76179b25-b6ba-4156-8bf6-47747593e7ac"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowExpectedSource/{global_data_set_row_expected_source_id}\"\n",
        "\n",
        "try:\n",
        "    # Perform the DELETE request\n",
        "    response = requests.delete(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d7bd647-56b4-4896-adde-8ee7662ce67a",
      "metadata": {
        "id": "6d7bd647-56b4-4896-adde-8ee7662ce67a"
      },
      "source": [
        "## Working with Filter Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4IALoH8CDtK",
      "metadata": {
        "id": "a4IALoH8CDtK"
      },
      "source": [
        "Filter variables allow you to define criteria for filtering dataset rows during evaluation. You can manage them using the following endpoints:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "254a0f4c-5004-4fa8-acf8-67ec17745d91",
      "metadata": {
        "id": "254a0f4c-5004-4fa8-acf8-67ec17745d91"
      },
      "source": [
        "### Listing Filter Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kT5B2Z31CJAi",
      "metadata": {
        "id": "kT5B2Z31CJAi"
      },
      "source": [
        "This endpoint retrieves a list of all filter variables for a specific dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f51edefa-c973-4d84-bee0-c809c6f7b18a",
      "metadata": {
        "id": "f51edefa-c973-4d84-bee0-c809c6f7b18a"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowFilterVariables\"\n",
        "\n",
        "try:\n",
        "    # Perform the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ea9aef-daf6-4c05-b5cd-3a9ac1a156c1",
      "metadata": {
        "id": "b5ea9aef-daf6-4c05-b5cd-3a9ac1a156c1"
      },
      "source": [
        "### Inserting a Filter Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2_AWQPfcCTTM",
      "metadata": {
        "id": "2_AWQPfcCTTM"
      },
      "source": [
        "This endpoint adds a new filter variable to a dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98df149-0981-43e7-a33e-3e0a773b2519",
      "metadata": {
        "id": "f98df149-0981-43e7-a33e-3e0a773b2519"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowFilterVariable\"\n",
        "\n",
        "# JSON data to be sent in the request body\n",
        "payload = {\n",
        "    \"dataSetMetadataType\": \"V\",\n",
        "    \"dataSetRowFilterKey\": \"KEY_C\",\n",
        "    \"dataSetRowFilterValue\": \"VALUE_C\",\n",
        "    \"dataSetRowFilterOperator\": \"OPERATOR_C\"\n",
        "}\n",
        "\n",
        "# Make the POST request\n",
        "try:\n",
        "    response = requests.post(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "\n",
        "        # Load the JSON response\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Extract the dataSetRowFilterVarId\n",
        "        data_set_row_filter_variable_id = response_data.get(\"dataSetRowFilterVarId\")\n",
        "\n",
        "        # Save it in a global variable or file\n",
        "        # Global variable\n",
        "        global_data_set_row_filter_variable_id = data_set_row_filter_variable_id  # This will be available in the Notebook\n",
        "\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c268678-2130-4bbf-bf6f-6d0a474a2580",
      "metadata": {
        "id": "6c268678-2130-4bbf-bf6f-6d0a474a2580"
      },
      "source": [
        "### Retrieving a Filter Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fGLp0_wdCYeK",
      "metadata": {
        "id": "fGLp0_wdCYeK"
      },
      "source": [
        "This endpoint retrieves a specific filter variable by its `Id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cc0e93-4ae3-434c-a170-6ebabf067076",
      "metadata": {
        "id": "88cc0e93-4ae3-434c-a170-6ebabf067076"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowFilterVariable/{global_data_set_row_filter_variable_id}\"\n",
        "\n",
        "try:\n",
        "    # Make the GET request\n",
        "    response = requests.get(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8788abb5-3089-48cb-ba37-9ebadfa5c0d1",
      "metadata": {
        "id": "8788abb5-3089-48cb-ba37-9ebadfa5c0d1"
      },
      "source": [
        "### Updating a Filter Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MEYkFpGeCfhu",
      "metadata": {
        "id": "MEYkFpGeCfhu"
      },
      "source": [
        "This endpoint updates an existing filter variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f59533-51cc-499b-b275-a8a52ecc87dd",
      "metadata": {
        "id": "a2f59533-51cc-499b-b275-a8a52ecc87dd"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowFilterVariable/{global_data_set_row_filter_variable_id}\"\n",
        "\n",
        "# JSON data to be sent in the body of the PUT request\n",
        "payload = {\n",
        "    \"dataSetMetadataType\": \"F\",\n",
        "    \"dataSetRowFilterKey\": \"KEY_D\",\n",
        "    \"dataSetRowFilterValue\": \"VALUE_D\",\n",
        "    \"dataSetRowFilterOperator\": \"OPERATOR_D\"\n",
        "}\n",
        "\n",
        "# Perform the PUT request\n",
        "try:\n",
        "    response = requests.put(url, json=payload, headers=headers, verify=False)\n",
        "\n",
        "    # Check the response code\n",
        "    if response.status_code == 200:\n",
        "        print(\"Request successful. Server response:\")\n",
        "        print(json.dumps(response.json(), indent=4))  # Print the response in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb8ee01-e920-4067-a446-c7ea61b08904",
      "metadata": {
        "id": "3cb8ee01-e920-4067-a446-c7ea61b08904"
      },
      "source": [
        "### Deleting a Filter Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rTBTenMKCjcx",
      "metadata": {
        "id": "rTBTenMKCjcx"
      },
      "source": [
        "This endpoint removes a filter variable from a dataset row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34149cd9-ddbf-4548-b763-38e9c6ede6bf",
      "metadata": {
        "id": "34149cd9-ddbf-4548-b763-38e9c6ede6bf"
      },
      "outputs": [],
      "source": [
        "# Service URL\n",
        "url = f\"{global_url}/dataSetApi/dataSet/{global_data_set_id}/dataSetRow/{global_data_set_row_id}/dataSetRowFilterVariable/{global_data_set_row_filter_variable_id}\"\n",
        "\n",
        "try:\n",
        "    # Perform the DELETE request\n",
        "    response = requests.delete(url, headers=headers, verify=False)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Service response:\")\n",
        "        print(response.json())  # If the response is in JSON format\n",
        "    else:\n",
        "        print(f\"Request error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error connecting to the service: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
