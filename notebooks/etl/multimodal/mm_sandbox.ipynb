{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal sandbox\n",
    "\n",
    "just testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: openai in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (1.40.8)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.32-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.3-cp310-cp310-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n",
      "  Downloading langchain_core-0.2.32-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.3.6-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.32->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.7-cp310-none-win_amd64.whl.metadata (51 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
      "Requirement already satisfied: colorama in c:\\proyectos\\ls_sandbox\\sandbox\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
      "   ---------------------------------------- 0.0/997.8 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 786.4/997.8 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 997.8/997.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.1.21-py3-none-any.whl (49 kB)\n",
      "Downloading aiohttp-3.10.3-cp310-cp310-win_amd64.whl (378 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.2.32-py3-none-any.whl (389 kB)\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.99-py3-none-any.whl (140 kB)\n",
      "Downloading SQLAlchemy-2.0.32-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.3 MB/s eta 0:00:00\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.7.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "Downloading aiohappyeyeballs-2.3.6-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.7-cp310-none-win_amd64.whl (137 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tenacity, orjson, multidict, jsonpointer, greenlet, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, tiktoken, SQLAlchemy, jsonpatch, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain_openai, langchain\n",
      "Successfully installed SQLAlchemy-2.0.32 aiohappyeyeballs-2.3.6 aiohttp-3.10.3 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.14 langchain-core-0.2.32 langchain-text-splitters-0.2.2 langchain_openai-0.1.21 langsmith-0.1.99 multidict-6.0.5 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path = \"C:/temp/saia/ge_excel_caso_brasil/\"\n",
    "image_urls = [\n",
    "    \"Image01.png\",\n",
    "    \"Image02.png\",\n",
    "    \"Image03.png\",\n",
    "    \"Image04.png\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "model_name = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "model = ChatOpenAI(model=model_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_sample = \"\"\"\n",
    "You will receive an image, in general from a Excel spreadsheet.\n",
    "\n",
    "You need to extract all the data as detailed as possible and write it down in a markdown format.\n",
    "\n",
    "Never include the markdown tag\n",
    "\n",
    "```markdown\n",
    "sample\n",
    "```\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número da FASP: 000\n",
      "\n",
      "Líder: Loren psun\n",
      "\n",
      "Título do Evento: Loren psun loren psun loren psun loren psun loren psun loren psun\n",
      "\n",
      "Local ou locais onde ocorreu o evento: Loren psun\n",
      "\n",
      "Turno: Loren psun\n",
      "\n",
      "Produto/Lote: Loren psun\n",
      "\n",
      "Data / Hora: 8/30/2023\n",
      "\n",
      "Quais pessoas viram o evento acontecer: Loren psun\n",
      "\n",
      "Descrição do Evento: (sem julgar ou tentar analisar, apenas DESCREVER)\n",
      "\n",
      "- O que ocorreu?: Loren psun\n",
      "- Quando?: 8/30/2023\n",
      "- Onde foi identificado?: Loren psun\n",
      "\n",
      "Ações imediatas (quais ações foram tomadas logo após o evento?):\n",
      "\n",
      "- Loren psun\n",
      "  - Quem tomou a ação?: Loren psun\n",
      "  - Data, Hora: 9/14/2023\n",
      "\n",
      "- Loren psun\n",
      "  - Quem tomou a ação?: Loren psun\n",
      "  - Data, Hora: 9/20/2023 \n",
      "\n",
      "\n",
      "ANÁLISE (do que pode ter sido a causa)\n",
      "\n",
      "PROVÁVEIS HIPÓTESES DO QUE PODE TER CAUSADO O EVENTO\n",
      "\n",
      "- **HIPÓTESE 1**\n",
      "  - Vendedor colocou o prazo errado no pedido\n",
      "\n",
      "- **HIPÓTESE 2**\n",
      "  - Erro de digitação do vendedor na hora de implantar o pedido\n",
      "\n",
      "- **HIPÓTESE 3**\n",
      "  - Cliente passou o prazo errado na ordem de compra\n",
      "\n",
      "- **HIPÓTESE 4**\n",
      "  - Vendedor não comparou o prazo da ordem compra enviada pelo cliente, com o valor negociado com o mesmo\n",
      "\n",
      "- **HIPÓTESE 5**\n",
      "  - Focal não conferiu o pedido junto a ordem de compras \n",
      "\n",
      "\n",
      "Fazer análise dos por quês somente das hipóteses mais prováveis\n",
      "\n",
      "| HIPÓTESE NÚMERO | 1º Por quê? | 2º Por quê? | 3º Por quê? | 4º Por quê? | 5º Por quê? |\n",
      "|-----------------|-------------|-------------|-------------|-------------|-------------|\n",
      "| Hipótese 1      | Colocou o prazo que utilizava nos pedidos anteriores | Não se lembrou que o cliente havia solicitado um novo prazo de pagamento | Não conferiu a ordem de compra do cliente | Não tem o hábito de fazer essa conferência |             |\n",
      "| Hipótese 5      | O vendedor não colocou a ordem de compra no pedido | Não foi solicitado pelo focal | Não tem o hábito de solicitar a ordem de compra para este cliente |             |             | \n",
      "\n",
      "\n",
      "| Item      | Plano de Ação                                                                                                                                                                | Resp.       | Prazo                                 |\n",
      "|-----------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------|---------------------------------------|\n",
      "| Hipótese 1 | Vendedor vai passar a controlar os prazos negociados com os clientes em uma planilha de excel. Principalmente para os clientes que compram com preços negociados para mais de três meses. | Lucas Slong | 10/6/2023                             |\n",
      "| Hipótese 1 | Vendedor se comprometeu a conferir os prazos nas ordens de compras com os valores negociados no momento da venda.                                                              | Lucas Slong | 10/6/2023                             |\n",
      "| Hipótese 4 | Focal irá colocar nas informações dos clientes no SIGA todos os prazos negociados entre o externo e com os clientes (Prazos Vigentes). Isso para os clientes Heve, Primato, Capal em um primeiro momento. Irá realizar a conferência também por essas informações. | Phelipe     | Aguardando envio das informações      |\n",
      "| Hipótese 4 | Caso os pedidos deste cliente entrem sem a ordem de compra em anexo, focal irá solicitar ao vendedor e após o envio fará a conferência.                                        | Phelipe     | 10/6/2023                             | \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for img in image_urls:\n",
    "    image_url = image_path + img\n",
    "\n",
    "    with open(image_url, 'rb') as file:\n",
    "        file_data = file.read()\n",
    "\n",
    "    image_data = base64.b64encode(file_data).decode(\"utf-8\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt_sample),\n",
    "            (\n",
    "                \"user\",\n",
    "                [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "                    }\n",
    "                ],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | model\n",
    "\n",
    "    response = chain.invoke({\"image_data\": image_data})\n",
    "    print(response.content, \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"image_data\": image_data})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
