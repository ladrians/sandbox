{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616d622d",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Dependencies to run the notebook\n",
    "\n",
    " * Install [ipykernel](https://pypi.org/project/ipykernel/).\n",
    " \n",
    "OCR and related \n",
    "\n",
    " * Install [tesseract](https://tesseract-ocr.github.io/tessdoc/Installation.html). Tested with tesseract-ocr-w64-setup-5.3.3.20231005.exe binary.\n",
    " * Install [pytesseract](https://pypi.org/project/pytesseract/).\n",
    " * Install [pdf2image](https://pypi.org/project/pdf2image/). Notice it has a dependency on [poppler](https://pdf2image.readthedocs.io/en/latest/installation.html#installing-poppler) follow the steps detailed and validate with the following command everything is set.\n",
    "\n",
    "```bash\n",
    "pdftoppm -h\n",
    "```\n",
    "\n",
    "Other dependencies\n",
    "\n",
    " * Install [openai](https://pypi.org/project/openai/).\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "```\n",
    "PDFInfoNotInstalledError: Unable to get page count.\n",
    "Is poppler installed and in PATH?\n",
    "```\n",
    "\n",
    "Make sure the PATH contains the full path to the poppler installation folder, for example:\n",
    "\n",
    "```\n",
    "C:\\temp\\utils\\poppler\\Library\\bin\\\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4c40d",
   "metadata": {},
   "source": [
    "The following commands needs to be executed only once or when you update dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efade90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipykernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ef131",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Snippet of what is needed to do.\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75742cc6-9b96-461a-a589-f809cf19e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d807ca-927e-4cc7-9701-cc700c2d11da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import image_to_string\n",
    "from tqdm import tqdm\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06ce9db-6634-4b6a-88e9-6f2df09b7576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afr',\n",
       " 'amh',\n",
       " 'ara',\n",
       " 'asm',\n",
       " 'aze',\n",
       " 'aze_cyrl',\n",
       " 'bel',\n",
       " 'ben',\n",
       " 'bod',\n",
       " 'bos',\n",
       " 'bre',\n",
       " 'bul',\n",
       " 'cat',\n",
       " 'ceb',\n",
       " 'ces',\n",
       " 'chi_sim',\n",
       " 'chi_sim_vert',\n",
       " 'chi_tra',\n",
       " 'chi_tra_vert',\n",
       " 'chr',\n",
       " 'cos',\n",
       " 'cym',\n",
       " 'dan',\n",
       " 'deu',\n",
       " 'div',\n",
       " 'dzo',\n",
       " 'ell',\n",
       " 'eng',\n",
       " 'enm',\n",
       " 'epo',\n",
       " 'equ',\n",
       " 'est',\n",
       " 'eus',\n",
       " 'fao',\n",
       " 'fas',\n",
       " 'fil',\n",
       " 'fin',\n",
       " 'fra',\n",
       " 'frk',\n",
       " 'frm',\n",
       " 'fry',\n",
       " 'gla',\n",
       " 'gle',\n",
       " 'glg',\n",
       " 'grc',\n",
       " 'guj',\n",
       " 'hat',\n",
       " 'heb',\n",
       " 'hin',\n",
       " 'hrv',\n",
       " 'hun',\n",
       " 'hye',\n",
       " 'iku',\n",
       " 'ind',\n",
       " 'isl',\n",
       " 'ita',\n",
       " 'ita_old',\n",
       " 'jav',\n",
       " 'jpn',\n",
       " 'jpn_vert',\n",
       " 'kan',\n",
       " 'kat',\n",
       " 'kat_old',\n",
       " 'kaz',\n",
       " 'khm',\n",
       " 'kir',\n",
       " 'kmr',\n",
       " 'kor',\n",
       " 'lao',\n",
       " 'lat',\n",
       " 'lav',\n",
       " 'lit',\n",
       " 'ltz',\n",
       " 'mal',\n",
       " 'mar',\n",
       " 'mkd',\n",
       " 'mlt',\n",
       " 'mon',\n",
       " 'mri',\n",
       " 'msa',\n",
       " 'mya',\n",
       " 'nep',\n",
       " 'nld',\n",
       " 'nor',\n",
       " 'oci',\n",
       " 'ori',\n",
       " 'osd',\n",
       " 'pan',\n",
       " 'pol',\n",
       " 'por',\n",
       " 'pus',\n",
       " 'que',\n",
       " 'ron',\n",
       " 'rus',\n",
       " 'san',\n",
       " 'sin',\n",
       " 'slk',\n",
       " 'slv',\n",
       " 'snd',\n",
       " 'spa',\n",
       " 'spa_old',\n",
       " 'sqi',\n",
       " 'srp',\n",
       " 'srp_latn',\n",
       " 'sun',\n",
       " 'swa',\n",
       " 'swe',\n",
       " 'syr',\n",
       " 'tam',\n",
       " 'tat',\n",
       " 'tel',\n",
       " 'tgk',\n",
       " 'tha',\n",
       " 'tir',\n",
       " 'ton',\n",
       " 'tur',\n",
       " 'uig',\n",
       " 'ukr',\n",
       " 'urd',\n",
       " 'uzb',\n",
       " 'uzb_cyrl',\n",
       " 'vie',\n",
       " 'yid',\n",
       " 'yor']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseract.get_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5178879e-aea6-4d50-8d9b-140a54969a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=api_key\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c0b07",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4801df46-7b70-42cb-aa22-b9905a93fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strings_to_file(strings, filename):\n",
    "    # Combine the strings into a single text\n",
    "    combined_text = ' '.join(strings)\n",
    "\n",
    "    # Write the text to a file\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(combined_text)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c49daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def get_text_from_pdf(pdf_path, language='eng'):\n",
    "    # Warning: other languages need to install other tesseract components\n",
    "    pages = convert_from_path(pdf_path)\n",
    "    ocr_pages = []\n",
    "    for i,page in enumerate(pages):\n",
    "        text = image_to_string(page, lang=language)\n",
    "        ocr_pages.append([text])\n",
    "        #page_footer = f\"---end of page {i+1}---\"\n",
    "        #print(page_footer)\n",
    "    print(f\"pages {i}\")\n",
    "    return ocr_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50866ef-edb6-41cd-a932-839d3f0bec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ungarble(text, model=\"gpt-4\"):\n",
    "    \n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ---- objective ----\n",
    "    fix the spacing and general layout of the following text and add needed words for it to make sense, only when they are incomplete, inintelligible or garbled\n",
    "    \n",
    "    ---- input format ----\n",
    "    text with incomplete words, wrong spacing, wrongly placed new lines and inconsistent formatting\n",
    "    \n",
    "    ---- output format ----\n",
    "    only fixed input, format, new lines and consistency in order to make it as readable as possible, no extra text or explanations\n",
    "\n",
    "    ---- input ----\n",
    "    {text}\n",
    "   \n",
    "    ---- output ----\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=4000,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "    )\n",
    "    \n",
    "    return  response.choices[0].message.content.strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c025899-8579-4379-aa5e-826f8dd90e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handle_text_from_pdf(pdf_path, language='eng', use_completion=False, model=\"gpt-4\"):\n",
    "    ocr_pages = get_text_from_pdf(pdf_path, language)\n",
    "\n",
    "    clean = []\n",
    "    for page in tqdm(ocr_pages):\n",
    "        text = ungarble(page[0], model) if use_completion else page[0]\n",
    "        clean.append(text)\n",
    "\n",
    "    output_path = f\"{pdf_path}.txt\"\n",
    "    result = write_strings_to_file(clean, output_path)\n",
    "    if result:\n",
    "        print(f\"Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9217c-a04f-483e-bc1c-e3dbb1ae893f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to C:/temp/saia/guyer/caso01/pregunta02/rch-EST-NCT-100000-17978787.pdf.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_completion = False # 30s\n",
    "#use_completion = True\n",
    "\n",
    "model = \"gpt-4\" # 4:30m\n",
    "model = \"gpt-4-turbo-preview\"\n",
    "model = \"gpt-3.5-turbo-16k\"\n",
    "model = \"gpt-3.5-turbo\" # 1:30m up to 4096 completion tokens\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "pdf_path = 'C:/tmp/test.pdf'\n",
    "language = 'spa'\n",
    "\n",
    "handle_text_from_pdf(pdf_path, language, use_completion, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf041be-c80d-4613-ba57-4da46e10a490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
