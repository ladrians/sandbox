{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKDlbcX9M8_x"
   },
   "source": [
    "# Minimal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BwpEalxgvlN",
    "outputId": "d9ec7e2a-d896-4d0a-b203-2619230e4adf"
   },
   "outputs": [],
   "source": [
    "!pip install llmsherpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy8mKt1NislJ"
   },
   "source": [
    "The first step in using the LayoutPDFReader is to provide a url or file path to it and get back a document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVCmWhxJiz9l"
   },
   "outputs": [],
   "source": [
    "from llmsherpa.readers import LayoutPDFReader\n",
    "\n",
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_url = \"C:/tmp/test.pdf\"\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "doc = pdf_reader.read_pdf(pdf_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YiiW2-Ni9HY"
   },
   "source": [
    "**Install LlamaIndex**\n",
    "\n",
    "In the following examples, we will use LlamaIndex for simplicity. Install the library if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbVGDukQjdRd",
    "outputId": "54f5ecd6-fca5-4ab4-84dd-881fdc748fc0"
   },
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqGIVd6qn6eC"
   },
   "source": [
    "**Setup OpenAI**\n",
    "\n",
    "Make sure your API Key is inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3E73STaElAwN"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = #insert your api key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY09Id11jXzp"
   },
   "source": [
    "**Summarize a Section using prompts**\n",
    "\n",
    "LayoutPDFReader offers powerful ways to pick sections and subsections from a large document and use LLMs to extract insights from a section.\n",
    "\n",
    "The following code looks for the Fine-tuning section of the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "yOAON0CDj1mC",
    "outputId": "c3264379-a792-46cc-822c-03f4e08e3c53"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "selected_section = None\n",
    "# find a section in the document by title\n",
    "for section in doc.sections():\n",
    "    if section.title == '3 Fine-tuning BART':\n",
    "        selected_section = section\n",
    "        break\n",
    "# use include_children=True and recurse=True to fully expand the section.\n",
    "# include_children only returns at one sublevel of children whereas recurse goes through all the descendants\n",
    "HTML(section.to_html(include_children=True, recurse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UnHxv2Ij-GO"
   },
   "source": [
    "Now, let's create a custom summary of this text using a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1-NOhTfkF3q",
    "outputId": "bd01f977-f56f-4103-af18-0c12141ef0db"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "context = selected_section.to_html(include_children=True, recurse=True)\n",
    "question = \"list all the tasks discussed and one line about each task\"\n",
    "resp = OpenAI().complete(f\"read this text and answer question: {question}:\\n{context}\")\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cs6WO91KlOkF"
   },
   "source": [
    "**Analyze a Table using prompts**\n",
    "\n",
    "With LayoutPDFReader, you can iterate through all the tables in a document and use the power of LLMs to analyze a Table Let's look at the 6th table in this document. If you are using a notebook, you can display the table as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "Wdqvkig-lX6g",
    "outputId": "aca3c0ad-498b-415d-e434-66f645e9a010"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "HTML(doc.tables()[5].to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NEl4vzvlg5W"
   },
   "source": [
    "Now let's ask a question to analyze this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7oHRsbcloL6",
    "outputId": "4b5b46df-bc01-49a2-ad75-dca4da50132a"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "context = doc.tables()[5].to_html()\n",
    "resp = OpenAI().complete(f\"read this table and answer question: which model has the best performance on squad 2.0:\\n{context}\")\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFefOzQ9ltM3"
   },
   "source": [
    "That's it! LayoutPDFReader also supports tables with nested headers and header rows.\n",
    "\n",
    "Here's an example with nested headers (note that the HTML doesn't render properly in ipython but the html structure is correct):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "SShVijKPlz36",
    "outputId": "e4435b65-1900-43b2-ac8f-0d7d42f95a43"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "HTML(doc.tables()[6].to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7F0GF1qNmJlS"
   },
   "source": [
    "Now let's ask an interesting question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsUCGpm3mRJJ",
    "outputId": "65c5136e-40a5-4ea1-a55b-b36eedefe050"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "context = doc.tables()[6].to_html()\n",
    "question = \"tell me about R1 of bart for different datasets\"\n",
    "resp = OpenAI().complete(f\"read this table and answer question: {question}:\\n{context}\")\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wE7I3L7XmWl3"
   },
   "source": [
    "\n",
    "**Vector search and Retrieval Augmented Generation with Smart Chunking**\n",
    "\n",
    "LayoutPDFReader does smart chunking keeping the integrity of related text together:\n",
    "\n",
    "All list items are together including the paragraph that precedes the list.\n",
    "Items in a table are chuncked together\n",
    "Contextual information from section headers and nested section headers is included\n",
    "The following code creates a LlamaIndex query engine from LayoutPDFReader document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGqsLP5zmirK",
    "outputId": "cb521786-ef48-4e95-8577-5a08e2c59b74"
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.schema.base import Document\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex([])\n",
    "for chunk in doc.chunks():\n",
    "    index.insert(Document(text=chunk.to_context_text(), extra_info={}))\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f797GR6nGKw"
   },
   "source": [
    "Let's run one query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vC9H9c38nOsG",
    "outputId": "bbbe1616-1765-41d9-fd71-997b9b380363"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"list all the tasks that work with bart\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ylioaL0nUyr"
   },
   "source": [
    "Let's try another query that needs answer from a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZEHBSsnnc30",
    "outputId": "db684d29-8757-4180-a922-ab7a14d07567"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"what is the bart performance score on squad\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YT67xijEnh1X"
   },
   "source": [
    "**Get the Raw JSON**\n",
    "\n",
    "To get the complete json returned by llmsherpa service and process it differently, simply get the json attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YHwKINfnri7",
    "outputId": "b676008e-2b25-40b8-d4fd-0e5bf6ba47df"
   },
   "outputs": [],
   "source": [
    "doc.json"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
