{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fab81f5-a0ca-4574-b656-5fd1719dde71",
   "metadata": {},
   "source": [
    "# Lesson 6: Shipping as a web API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f6254b-5eaf-4867-999b-97d08f96cee9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] { default: {} }"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \"dotenv/config\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c326a7cc-d9be-432c-be10-7846d2b8e5e9",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "import { \n",
    "  loadAndSplitChunks, \n",
    "  initializeVectorstoreWithDocuments \n",
    "} from \"./lib/helpers.ts\";\n",
    "\n",
    "const splitDocs = await loadAndSplitChunks({\n",
    "  chunkSize: 1536,\n",
    "  chunkOverlap: 128,\n",
    "});\n",
    "\n",
    "const vectorstore = await initializeVectorstoreWithDocuments({\n",
    "  documents: splitDocs,\n",
    "});\n",
    "\n",
    "const retriever = vectorstore.asRetriever();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b25e21c-28d0-4329-852e-b96a14c38529",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "import { \n",
    "  createDocumentRetrievalChain, \n",
    "  createRephraseQuestionChain \n",
    "} from \"./lib/helpers.ts\";\n",
    "\n",
    "const documentRetrievalChain = createDocumentRetrievalChain();\n",
    "const rephraseQuestionChain = createRephraseQuestionChain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520b4a9b-89de-4652-b238-b7dddbd5a2c2",
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
    "\n",
    "const ANSWER_CHAIN_SYSTEM_TEMPLATE = `You are an experienced researcher,\n",
    "expert at interpreting and answering questions based on provided sources.\n",
    "Using the below provided context and chat history, \n",
    "answer the user's question to the best of your ability\n",
    "using only the resources provided. Be verbose!\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>`;\n",
    "\n",
    "const answerGenerationChainPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", ANSWER_CHAIN_SYSTEM_TEMPLATE],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\n",
    "    \"human\", \n",
    "    `Now, answer this question using the previous context and chat history:\n",
    "  \n",
    "    {standalone_question}`\n",
    "  ]\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c325c8b5-9292-41f2-ad10-3ad0ad3df182",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "import { \n",
    "  RunnablePassthrough, \n",
    "  RunnableSequence \n",
    "} from \"@langchain/core/runnables\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const conversationalRetrievalChain = RunnableSequence.from([\n",
    "  RunnablePassthrough.assign({\n",
    "    standalone_question: rephraseQuestionChain,\n",
    "  }),\n",
    "  RunnablePassthrough.assign({\n",
    "    context: documentRetrievalChain,\n",
    "  }),\n",
    "  answerGenerationChainPrompt,\n",
    "  new ChatOpenAI({ modelName: \"gpt-3.5-turbo-1106\" }),\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fe1d4c-9075-47d4-8451-b9bbc1115668",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import { HttpResponseOutputParser } from \"langchain/output_parsers\";\n",
    "\n",
    "// \"text/event-stream\" is also supported\n",
    "const httpResponseOutputParser = new HttpResponseOutputParser({\n",
    "  contentType: \"text/plain\"\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb3853d-826c-4e1f-a413-9f9f0faf62fe",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\"; \n",
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
    "\n",
    "const messageHistory = new ChatMessageHistory();\n",
    "\n",
    "const finalRetrievalChain = new RunnableWithMessageHistory({\n",
    "  runnable: conversationalRetrievalChain,\n",
    "  getMessageHistory: (_sessionId) => messageHistory,\n",
    "  historyMessagesKey: \"history\",\n",
    "  inputMessagesKey: \"question\",\n",
    "}).pipe(httpResponseOutputParser);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaeb6ee-d3a0-4adb-b08c-e78a7ef92321",
   "metadata": {},
   "source": [
    "Additionally, we'll want to bear in mind that users should not share chat histories, and we should create a new history object per session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f81c9f-88d7-470a-b597-c4137c9d35a4",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "const messageHistories = {};\n",
    "\n",
    "const getMessageHistoryForSession = (sessionId) => {\n",
    "    if (messageHistories[sessionId] !== undefined) {\n",
    "        return messageHistories[sessionId];\n",
    "    } \n",
    "    const newChatSessionHistory = new ChatMessageHistory();\n",
    "    messageHistories[sessionId] = newChatSessionHistory;\n",
    "    return newChatSessionHistory;\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7291e9-6448-4931-bd56-f905f6324b4e",
   "metadata": {},
   "source": [
    "We'll recreate our final chain with this new method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24bc88b0-851c-4304-a085-ac0cba9f615f",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "const finalRetrievalChain = new RunnableWithMessageHistory({\n",
    "  runnable: conversationalRetrievalChain,\n",
    "  getMessageHistory: getMessageHistoryForSession,\n",
    "  inputMessagesKey: \"question\",\n",
    "  historyMessagesKey: \"history\",\n",
    "}).pipe(httpResponseOutputParser);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35a5209-e820-496b-9abc-60ade9f22d7c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "const port = 8087;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc26867-8376-4358-9525-221227967091",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "const handler = async (request: Request): Response => {\n",
    "  const body = await request.json();\n",
    "  const stream = await finalRetrievalChain.stream({\n",
    "    question: body.question\n",
    "  }, { configurable: { sessionId: body.session_id } });\n",
    "\n",
    "  return new Response(stream, { \n",
    "    status: 200,\n",
    "    headers: {\n",
    "      \"Content-Type\": \"text/plain\"\n",
    "    },\n",
    "  });\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac36205-de1c-4cfb-81e8-9c9d1525b338",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening on http://localhost:8087/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  finished: Promise { \u001b[36m<pending>\u001b[39m },\n",
       "  shutdown: \u001b[36m[AsyncFunction: shutdown]\u001b[39m,\n",
       "  ref: \u001b[36m[Function: ref]\u001b[39m,\n",
       "  unref: \u001b[36m[Function: unref]\u001b[39m,\n",
       "  [\u001b[32mSymbol(Symbol.asyncDispose)\u001b[39m]: \u001b[36m[Function: [Symbol.asyncDispose]]\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deno.serve({ port }, handler);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b547772d-4f1f-48e8-b381-138b30d993af",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "const decoder = new TextDecoder();\n",
    "\n",
    "// readChunks() reads from the provided reader and yields the results into an async iterable\n",
    "function readChunks(reader) {\n",
    "  return {\n",
    "    async* [Symbol.asyncIterator]() {\n",
    "      let readResult = await reader.read();\n",
    "      while (!readResult.done) {\n",
    "        yield decoder.decode(readResult.value);\n",
    "        readResult = await reader.read();\n",
    "      }\n",
    "    },\n",
    "  };\n",
    "}\n",
    "\n",
    "const sleep = async () => {\n",
    "  return new Promise((resolve) => setTimeout(resolve, 500));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac25b85d-dd40-42a1-8374-6c778e86c9d8",
   "metadata": {
    "height": 353
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK: Based on the \n",
      "CHUNK: provided\n",
      "CHUNK:  context,\n",
      "CHUNK:  the requireme\n",
      "CHUNK: nts for the co\n",
      "CHUNK: urse are as fo\n",
      "CHUNK: llows:\n",
      "\n",
      "\n",
      "CHUNK: 1. Famil\n",
      "CHUNK: iarity wi\n",
      "CHUNK: th basic probab\n",
      "CHUNK: ility and stati\n",
      "CHUNK: stics: The\n",
      "CHUNK:  instruc\n",
      "CHUNK: tor assum\n",
      "CHUNK: es that most u\n",
      "CHUNK: ndergrad\n",
      "CHUNK: uate statistics cla\n",
      "CHUNK: sses, lik\n",
      "CHUNK: e Stat 116 at\n",
      "CHUNK:  Stanford, wil\n",
      "CHUNK: l be mor\n",
      "CHUNK: e than enough.\n",
      "CHUNK:  Students \n",
      "CHUNK: are expected to k\n",
      "CHUNK: now about rando\n",
      "CHUNK: m variab\n",
      "CHUNK: les, expectati\n",
      "CHUNK: ons, variance,\n",
      "CHUNK:  and other rel\n",
      "CHUNK: ated concept\n",
      "CHUNK: s. The instructor also\n",
      "CHUNK:  mentions that\n",
      "CHUNK:  they will go\n",
      "CHUNK:  over the pre\n",
      "CHUNK: requisites in s\n",
      "CHUNK: ome discussion\n",
      "CHUNK:  sections\n",
      "CHUNK:  as a refresher course.\n",
      "CHUNK: \n",
      "\n",
      "2. Familiarity with basic lin\n",
      "CHUNK: ear algebra: \n",
      "CHUNK: Most undergraduate linear algebra courses\n",
      "CHUNK: , such as Math 51\n",
      "CHUNK: , 103, Math \n",
      "CHUNK: 113, or CS205\n",
      "CHUNK:  at Stanford, are conside\n",
      "CHUNK: red to be more than enough. Students are expected to be f\n",
      "CHUNK: amiliar with matrices, ve\n",
      "CHUNK: ctors, matrix mul\n",
      "CHUNK: tiplication, matrix \n",
      "CHUNK: inverses, and \n",
      "CHUNK: possibly eig\n",
      "CHUNK: envectors of a\n",
      "CHUNK:  matrix.\n",
      "\n",
      "3. The \n",
      "CHUNK: course will involve some programming, mostly in either MATLAB or Octave. The course is not very programming intensive, but students will engage in programming activities.\n",
      "\n",
      "These are the main requirements for the course as outlined by the instructor in the provided context.\n"
     ]
    }
   ],
   "source": [
    "const response = await fetch(`http://localhost:${port}`, {\n",
    "    method: \"POST\",\n",
    "    headers: {\n",
    "        \"content-type\": \"application/json\",\n",
    "    },\n",
    "    body: JSON.stringify({\n",
    "        question: \"What are the prerequisites for this course?\",\n",
    "        session_id: \"1\", // Should randomly generate/assign\n",
    "    })\n",
    "});\n",
    "\n",
    "// response.body is a ReadableStream\n",
    "const reader = response.body?.getReader();\n",
    "\n",
    "for await (const chunk of readChunks(reader)) {\n",
    "  console.log(\"CHUNK:\", chunk);\n",
    "}\n",
    "\n",
    "await sleep();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af107da-cf4c-4900-a456-d131ff8fbc80",
   "metadata": {
    "height": 353
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK: The prerequi\n",
      "CHUNK: sites for\n",
      "CHUNK:  this course, as out\n",
      "CHUNK: lined by th\n",
      "CHUNK: e instru\n",
      "CHUNK: ctor in\n",
      "CHUNK:  the provided \n",
      "CHUNK: context, \n",
      "CHUNK: can be summarize\n",
      "CHUNK: d in bullet\n",
      "CHUNK:  point forma\n",
      "CHUNK: t as follows\n",
      "CHUNK: :\n",
      "\n",
      "- Fam\n",
      "CHUNK: iliarity with\n",
      "CHUNK:  basic probability \n",
      "CHUNK: and statistics\n",
      "CHUNK: , including \n",
      "CHUNK: knowledge\n",
      "CHUNK:  of rand\n",
      "CHUNK: om variables, e\n",
      "CHUNK: xpectations,\n",
      "CHUNK:  variances, and rel\n",
      "CHUNK: ated concepts\n",
      "CHUNK: . Most under\n",
      "CHUNK: graduate statistics \n",
      "CHUNK: classes, such\n",
      "CHUNK:  as Stat 11\n",
      "CHUNK: 6 at Stanford\n",
      "CHUNK: , are con\n",
      "CHUNK: sidered s\n",
      "CHUNK: ufficient\n",
      "CHUNK:  preparation.\n",
      "CHUNK: \n",
      "- Familiarity with basic linear alge\n",
      "CHUNK: bra, including under\n",
      "CHUNK: standing of\n",
      "CHUNK:  matrices, vectors,\n",
      "CHUNK:  matrix mult\n",
      "CHUNK: iplication\n",
      "CHUNK: , matrix inver\n",
      "CHUNK: ses, and possibly ei\n",
      "CHUNK: genvectors of a\n",
      "CHUNK:  matrix. Most undergraduate linear algebra course\n",
      "CHUNK: s, such as Math 51, 103, Math 113, or CS205 at Stanford, are deemed adequate for this course.\n",
      "- Some programming experience, with an emphasis on MATLAB or Octave. The course will involve programming activities, but it is not considered very programming intensive.\n"
     ]
    }
   ],
   "source": [
    "const response = await fetch(`http://localhost:${port}`, {\n",
    "  method: \"POST\",\n",
    "  headers: {\n",
    "    \"content-type\": \"application/json\",\n",
    "  },\n",
    "  body: JSON.stringify({\n",
    "    question: \"Can you list them in bullet point format?\",\n",
    "    session_id: \"1\", // Should randomly generate/assign\n",
    "  })\n",
    "});\n",
    "\n",
    "// response.body is a ReadableStream\n",
    "const reader = response.body?.getReader();\n",
    "\n",
    "for await (const chunk of readChunks(reader)) {\n",
    "  console.log(\"CHUNK:\", chunk);\n",
    "}\n",
    "\n",
    "await sleep();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbcaa28f-5057-4109-80c1-406ec47bd9eb",
   "metadata": {
    "height": 353
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK: Based on \n",
      "CHUNK: the provide\n",
      "CHUNK: d context, you\n",
      "CHUNK:  did not \n",
      "CHUNK: explicit\n",
      "CHUNK: ly ask a que\n",
      "CHUNK: stion i\n",
      "CHUNK: n the immedia\n",
      "CHUNK: te previous c\n",
      "CHUNK: hat. Ins\n",
      "CHUNK: tead, the user\n",
      "CHUNK:  in the context is Andr\n",
      "CHUNK: ew Ng, the i\n",
      "CHUNK: nstructor,\n",
      "CHUNK:  along with\n",
      "CHUNK:  students\n",
      "CHUNK:  in a classroom\n",
      "CHUNK:  setting\n",
      "CHUNK: . The convers\n",
      "CHUNK: ation highli\n",
      "CHUNK: ghted students men\n",
      "CHUNK: tioning their a\n",
      "CHUNK: reas of\n",
      "CHUNK:  study such as st\n",
      "CHUNK: atistics, iCME, \n",
      "CHUNK: Civi, Syn\n",
      "CHUNK: thesis, C\n",
      "CHUNK: hemi, Aero/Astro, \n",
      "CHUNK: MSNE, an\n",
      "CHUNK: d industry.\n",
      "CHUNK:  Andrew Ng acknowle\n",
      "CHUNK: dges the d\n",
      "CHUNK: iversity\n",
      "CHUNK:  of the audience in the class. Therefore, based on the available context, there wasn't a question specifically asked by you in the previous chat. If there was a different specific question, or if additional context is provided, I would be happy to assist further.\n"
     ]
    }
   ],
   "source": [
    "const response = await fetch(`http://localhost:${port}`, {\n",
    "  method: \"POST\",\n",
    "  headers: {\n",
    "    \"content-type\": \"application/json\",\n",
    "  },\n",
    "  body: JSON.stringify({\n",
    "    question: \"What did I just ask you?\",\n",
    "    session_id: \"2\", // Should randomly generate/assign\n",
    "  })\n",
    "});\n",
    "\n",
    "// response.body is a ReadableStream\n",
    "const reader = response.body?.getReader();\n",
    "\n",
    "for await (const chunk of readChunks(reader)) {\n",
    "  console.log(\"CHUNK:\", chunk);\n",
    "}\n",
    "\n",
    "await sleep();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b5f7d-75e0-4366-8adf-48053f19229d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
